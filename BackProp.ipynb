{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BackProp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt1MQtNtLPg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#BackPropLab\n",
        "import numpy as np\n",
        "\n",
        "k = 1\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1.0 + np.exp(-k*x))\n",
        "\n",
        "#mistake was here\n",
        "def sigmoid_prime(x):\n",
        "    return x*(1.0 - x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return 1.0 - x**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdEXxJUzW8gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7e31db23-d5ae-4b68-9a99-dacced92ae4c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        self.activation = sigmoid\n",
        "        self.activation_prime = sigmoid_prime\n",
        "        self.output_errors = []\n",
        "        # self.activation = tanh\n",
        "        # self.activation_prime = tanh_prime\n",
        "\n",
        "        # Set weights\n",
        "        self.weights = []\n",
        "        # layers = [2,2,1]\n",
        "        # range of weight values (-1,1)\n",
        "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
        "        \n",
        "        for i in range(1, len(layers) - 1):\n",
        "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
        "            self.weights.append(r)\n",
        "            print(r)\n",
        "        # output layer - random((2+1, 1)) : 3 x 1\n",
        "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
        "        print(r)\n",
        "        self.weights.append(r)\n",
        "\n",
        "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
        "        # Add column of ones to X\n",
        "        # This is to add the bias unit to the input layer\n",
        "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
        "        X = np.concatenate((ones.T, X), axis=1)\n",
        "        for k in range(epochs):\n",
        "            i = np.random.randint(X.shape[0])\n",
        "            a = [X[i]]\n",
        "\n",
        "            for l in range(len(self.weights)):\n",
        "                    dot_value = np.dot(a[l], self.weights[l])\n",
        "                    activation = self.activation(dot_value)\n",
        "                    a.append(activation)\n",
        "            # output layer\n",
        "            error = y[i] - a[-1]\n",
        "            #take errors\n",
        "            self.output_errors.append(error)\n",
        "            deltas = [error * self.activation_prime(a[-1])]\n",
        "\n",
        "            # we have to start at the second to last layer \n",
        "            # (a layer before the output layer)\n",
        "            for l in range(len(a) - 2, 0, -1): \n",
        "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
        "\n",
        "            # reverse\n",
        "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
        "            deltas.reverse()\n",
        "\n",
        "            # backpropagation\n",
        "            # 1. Multiply its output delta and input activation \n",
        "            #    to get the gradient of the weight.\n",
        "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
        "            for i in range(len(self.weights)):\n",
        "                layer = np.atleast_2d(a[i])\n",
        "                delta = np.atleast_2d(deltas[i])\n",
        "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
        "\n",
        "            if k % 10000 == 0: \n",
        "                print('epochs:', k)\n",
        "\n",
        "    def predict(self, x): \n",
        "    \n",
        "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
        "\n",
        "        for l in range(0, len(self.weights)):\n",
        "            a = self.activation(np.dot(a, self.weights[l]))\n",
        "        return a\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    nn = NeuralNetwork([2,2,1])\n",
        "    X = np.array([[0, 0],\n",
        "                  [0, 1],\n",
        "                  [1, 0],\n",
        "                  [1, 1]])\n",
        "    y = np.array([0, 1, 1, 0])\n",
        "#     X = np.array([[-1, -1],\n",
        "#                   [-1, 1],\n",
        "#                   [1, -1],\n",
        "#                   [1, 1]])\n",
        "#     y = np.array([0, 1, 1, 0])\n",
        "\n",
        "    nn.fit(X, y)\n",
        "    for e in X:\n",
        "        print(e,nn.predict(e))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.45875193  0.85631472 -0.86862434]\n",
            " [-0.61045206  0.46471448 -0.97769141]\n",
            " [ 0.33384902 -0.3850128  -0.89883117]]\n",
            "[[-0.28800278]\n",
            " [ 0.37500644]\n",
            " [-0.23247113]]\n",
            "epochs: 0\n",
            "epochs: 10000\n",
            "epochs: 20000\n",
            "epochs: 30000\n",
            "epochs: 40000\n",
            "epochs: 50000\n",
            "epochs: 60000\n",
            "epochs: 70000\n",
            "epochs: 80000\n",
            "epochs: 90000\n",
            "[0 0] [0.01510101]\n",
            "[0 1] [0.97959862]\n",
            "[1 0] [0.98817188]\n",
            "[1 1] [0.02266336]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaRlJt9kXSC0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "82914126-5210-48c6-ce45-191722cefb60"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "#x = np.linspace(-10.0,10.0,100)\n",
        "x = np.linspace(0,100000,100000)\n",
        "#sig = sigmoid_prime(x)\n",
        "error = nn.output_errors\n",
        "plt.plot(x,error)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3ac8bbbe48>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD5CAYAAAAuneICAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}